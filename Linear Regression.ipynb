{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression using Google's TensorFlow API for machine learning. The following example shows how usual linear regression is done in the machine learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear regression\n",
    "\n",
    "A simple linear regression model in the statistician's language is: \n",
    "\n",
    "$$Y \\sim \\beta_0 + \\beta_1 X,$$\n",
    "\n",
    "where $X$ is the (single) independent variable and $Y$ is the dependent variable, and the $\\beta$ are the fitting coefficients ($\\beta_0$ is the intersection and $\\beta_1$ is the slope).\n",
    "\n",
    "This problem translates to the machine learner's language as\n",
    "\n",
    "$$y = W x + b$$\n",
    "\n",
    "where $x$ is the the (single) feature, $y$ is the prediction, $W$ is the so-called weight matrix (in this case it is a scalar since the problem is one-dimensional), and $b$ is the so-called bias. \n",
    "\n",
    "Oftentimes, there are multiple independent variables explaining the change in the dependent variable, or multiple features in machine learning language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, import the TensorFlow library for handling matrix operations and learning, and NumPy for random number generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 100 x, y data points in NumPy such that y = 0.1 * x + 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = 0.1 * x_data + 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to find values for W and b that compute $y = W x + b$\n",
    "(We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "figure that out for us.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the error of the fit by the sum of the square of the error on each training example, also called the loss function, and minimize this mean squared error loss function to get the $W$ weight and $b$ bias. We pick a gradient descent optmizer as our optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, initialize the variables.  We will 'run' this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a TensorFlow session and now actually run the initialization in this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we do the actual fitting or learning step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.37464312] [ 0.20471518]\n",
      "20 [ 0.15745121] [ 0.26863849]\n",
      "40 [ 0.11311522] [ 0.29284066]\n",
      "60 [ 0.10299401] [ 0.29836565]\n",
      "80 [ 0.1006835] [ 0.29962692]\n",
      "100 [ 0.10015604] [ 0.29991484]\n",
      "120 [ 0.10003562] [ 0.29998058]\n",
      "140 [ 0.10000815] [ 0.29999557]\n",
      "160 [ 0.10000186] [ 0.299999]\n",
      "180 [ 0.10000042] [ 0.29999977]\n",
      "200 [ 0.1000001] [ 0.29999995]\n"
     ]
    }
   ],
   "source": [
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))\n",
    "\n",
    "# Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 201)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
